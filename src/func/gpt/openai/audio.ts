import { appendLog } from "../MessageLogger";
import { FormatConverter, formatFileSize } from "../chat-utils/msg-modal";

// ============================================================================
// Audio Transcription Types (Speech-to-Text)
// ============================================================================

export interface IAudioTranscriptionOptions {
    file: File | Blob;
    model: string;
    language?: string;
    prompt?: string;
    response_format?: "json" | "text" | "srt" | "verbose_json" | "vtt";
    temperature?: number;
    timestamp_granularities?: ("word" | "segment")[];
    [key: string]: any;
}

export interface IAudioTranscriptionResult {
    ok?: boolean;
    text?: string;
    language?: string;
    duration?: number;
    words?: Array<{
        word: string;
        start: number;
        end: number;
    }>;
    segments?: Array<{
        id: number;
        start: number;
        end: number;
        text: string;
    }>;
    error?: string;
}

// ============================================================================
// Text-to-Speech Types
// ============================================================================

export interface ITextToSpeechOptions {
    input: string;
    model?: string;
    voice: "alloy" | "echo" | "fable" | "onyx" | "nova" | "shimmer";
    response_format?: "mp3" | "opus" | "aac" | "flac" | "wav" | "pcm";
    speed?: number;
    [key: string]: any;
}

export interface ITextToSpeechResult {
    ok?: boolean;
    audio?: Blob;
    audioUrl?: string;
    error?: string;
    format?: string;
    duration?: number;
}

// ============================================================================
// Audio Transcription Implementation (Speech-to-Text)
// ============================================================================

/**
 * Transcribe audio to text using Whisper
 * @param runtimeModel - Runtime LLM configuration
 * @param options - Audio transcription options
 * @returns Promise with transcription result
 */
export const transcribeAudio = async (
    runtimeModel: IRuntimeLLM,
    options: IAudioTranscriptionOptions
): Promise<IAudioTranscriptionResult> => {
    if (!runtimeModel) {
        return {
            ok: false,
            error: 'Error: æ— æ³•è·å–éŸ³é¢‘è½¬å½•æ¨¡å‹ï¼Œè¯·å…ˆåœ¨è®¾ç½®ä¸­æ·»åŠ å¹¶é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ã€‚'
        };
    }

    try {
        const { url, apiKey, provider } = runtimeModel;

        const knownParams = ['file', 'model', 'language', 'prompt', 'response_format', 'temperature', 'timestamp_granularities'];

        // Get the endpoint for audio transcriptions
        // const endpoint = provider?.endpoints?.audio_transcriptions || '/audio/transcriptions';
        // const fullUrl = url.endsWith(endpoint) ? url : `${url}${endpoint}`;
        const fullUrl = url;

        // Build FormData for multipart/form-data request
        const formData = new FormData();
        formData.append('file', options.file);
        formData.append('model', runtimeModel.model);

        if (options.language) formData.append('language', options.language);
        if (options.prompt) formData.append('prompt', options.prompt);
        if (options.response_format) formData.append('response_format', options.response_format);
        if (options.temperature !== undefined) formData.append('temperature', options.temperature.toString());
        if (options.timestamp_granularities) {
            options.timestamp_granularities.forEach(granularity => {
                formData.append('timestamp_granularities[]', granularity);
            });
        }

        // Add custom parameters
        Object.keys(options).forEach(key => {
            if (!knownParams.includes(key)) {
                console.log(`[Audio Transcription] Custom parameter passed: ${key}`, options[key]);
                formData.append(key, options[key]);
            }
        });

        appendLog({
            type: 'request', data: {
                hasAudioFile: true,
                model: options.model,
                language: options.language,
                response_format: options.response_format
            }
        });

        const response = await fetch(fullUrl, {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${apiKey}`,
                ...(provider?.customHeaders || {})
            },
            body: formData
        });

        if (!response.ok) {
            const errorData = await response.json().catch(() => null);
            appendLog({ type: 'response', data: errorData });
            return {
                ok: false,
                error: errorData ? JSON.stringify(errorData) : `HTTP error! status: ${response.status}`
            };
        }

        // Handle different response formats
        const responseFormat = options.response_format || 'json';
        let result: IAudioTranscriptionResult;

        if (responseFormat === 'text') {
            const text = await response.text();
            result = {
                ok: true,
                text: text
            };
        } else if (responseFormat === 'verbose_json') {
            const data = await response.json();
            result = {
                ok: true,
                text: data.text,
                language: data.language,
                duration: data.duration,
                words: data.words,
                segments: data.segments?.map((seg: any) => ({
                    id: seg.id,
                    start: seg.start,
                    end: seg.end,
                    text: seg.text
                }))
            };
        } else if (responseFormat === 'srt' || responseFormat === 'vtt') {
            const text = await response.text();
            result = {
                ok: true,
                text: text
            };
        } else {
            const data = await response.json();
            result = {
                ok: true,
                text: data.text
            };
        }

        appendLog({ type: 'response', data: result });
        return result;

    } catch (error) {
        return {
            ok: false,
            error: `Failed to transcribe audio: ${error}`
        };
    }
};

// ============================================================================
// Text-to-Speech Implementation
// ============================================================================

/**
 * Generate speech from text using TTS
 * @param runtimeModel - Runtime LLM configuration
 * @param options - Text-to-speech options
 * @returns Promise with audio result
 */
export const textToSpeech = async (
    runtimeModel: IRuntimeLLM,
    options: ITextToSpeechOptions
): Promise<ITextToSpeechResult> => {
    if (!runtimeModel) {
        return {
            ok: false,
            error: 'Error: æ— æ³•è·å–è¯­éŸ³åˆæˆæ¨¡å‹ï¼Œè¯·å…ˆåœ¨è®¾ç½®ä¸­æ·»åŠ å¹¶é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ã€‚'
        };
    }

    try {
        const { url: fullUrl, apiKey, provider } = runtimeModel;

        const knownParams = ['input', 'model', 'voice', 'response_format', 'speed'];

        // Get the endpoint for audio speech
        // const endpoint = provider?.endpoints?.audio_speech || '/audio/speech';
        // const fullUrl = url.endsWith(endpoint) ? url : `${url}${endpoint}`;

        // Build request payload
        const payload: any = {
            input: options.input,
            model: runtimeModel.model,
            voice: options.voice,
        };

        if (options.response_format) payload.response_format = options.response_format;
        if (options.speed !== undefined) payload.speed = options.speed;

        // Add custom parameters
        Object.keys(options).forEach(key => {
            if (!knownParams.includes(key)) {
                console.log(`[Text To Speech] Custom parameter passed: ${key}`, options[key]);
                payload[key] = options[key];
            }
        });

        appendLog({ type: 'request', data: payload });

        const response = await fetch(fullUrl, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`,
                ...(provider?.customHeaders || {})
            },
            body: JSON.stringify(payload)
        });

        if (!response.ok) {
            const errorData = await response.json().catch(() => null);
            appendLog({ type: 'response', data: errorData });
            return {
                ok: false,
                error: errorData ? JSON.stringify(errorData) : `HTTP error! status: ${response.status}`
            };
        }

        // Get audio as Blob
        const audioBlob = await response.blob();

        // ä½¿ç”¨ Blob URL è€Œä¸æ˜¯ DataURLï¼Œé¿å…å ç”¨å¤§é‡æ–‡æœ¬ç©ºé—´
        // è®¾ç½® 10 åˆ†é’Ÿåè‡ªåŠ¨å›æ”¶ï¼Œç»™ç”¨æˆ·è¶³å¤Ÿæ—¶é—´æ’­æ”¾å’Œä¸‹è½½ï¼Œé¿å…é•¿æœŸå ç”¨å†…å­˜
        const audioBlobURL = FormatConverter.blobToObjectURL(audioBlob, {
            seconds: 6000
        });

        appendLog({ type: 'response', data: { audioGenerated: true, size: audioBlob.size } });

        return {
            ok: true,
            audio: audioBlob,
            audioUrl: audioBlobURL, // ä½¿ç”¨ Blob URLï¼ˆè½»é‡çº§ï¼‰
            format: options.response_format || 'mp3'
        };

    } catch (error) {
        return {
            ok: false,
            error: `Failed to generate speech: ${error}`
        };
    }
};

// ============================================================================
// Conversion to ICompletionResult
// ============================================================================

/**
 * Convert IAudioTranscriptionResult to ICompletionResult for display in chat
 * @param transcriptionResult - Audio transcription result
 * @param options - Conversion options
 * @returns ICompletionResult with transcribed text and timestamps
 */
export const transcriptionResultToCompletion = (
    transcriptionResult: IAudioTranscriptionResult,
    options?: {
        showTimestamps?: boolean;
        showSegments?: boolean;
    }
): ICompletionResult => {
    if (!transcriptionResult.ok) {
        return {
            ok: false,
            content: `**éŸ³é¢‘è½¬å½•å¤±è´¥**\n\n${transcriptionResult.error}`,
            usage: null
        };
    }

    const lines: string[] = [];

    // Add metadata
    const metadata: string[] = [];
    if (transcriptionResult.language) metadata.push(`è¯­è¨€: ${transcriptionResult.language}`);
    if (transcriptionResult.duration) {
        const minutes = Math.floor(transcriptionResult.duration / 60);
        const seconds = Math.floor(transcriptionResult.duration % 60);
        metadata.push(`æ—¶é•¿: ${minutes}:${seconds.toString().padStart(2, '0')}`);
    }

    if (metadata.length > 0) {
        lines.push(`*${metadata.join(' | ')}*\n`);
    }

    // Add transcribed text - ä½¿ç”¨æŠ˜å å¤„ç†é•¿æ–‡æœ¬
    const text = transcriptionResult.text || '';
    const MAX_PREVIEW_LENGTH = 200;

    lines.push(`### è½¬å½•æ–‡æœ¬\n`);

    if (text.length <= MAX_PREVIEW_LENGTH) {
        // çŸ­æ–‡æœ¬ç›´æ¥æ˜¾ç¤º
        lines.push(text);
    } else {
        // é•¿æ–‡æœ¬ä½¿ç”¨ details æŠ˜å 
        const preview = text.substring(0, MAX_PREVIEW_LENGTH);
        lines.push(`${preview}...`);
        lines.push(`\n<details><summary>ğŸ“„ å±•å¼€å®Œæ•´æ–‡æœ¬ (${text.length} å­—ç¬¦)</summary>\n`);
        lines.push('```txt');
        lines.push(text);
        lines.push('```');
        lines.push('</details>');
    }

    // Add timestamps if requested and available
    if (options?.showTimestamps && transcriptionResult.words && transcriptionResult.words.length > 0) {
        lines.push(`\n### è¯çº§æ—¶é—´æˆ³\n`);
        lines.push('<details><summary>ğŸ“Š å±•å¼€æŸ¥çœ‹æ—¶é—´æˆ³</summary>\n');
        transcriptionResult.words.forEach(word => {
            const start = word.start.toFixed(2);
            const end = word.end.toFixed(2);
            lines.push(`- **${word.word}** \`[${start}s - ${end}s]\``);
        });
        lines.push('</details>');
    }

    // Add segments if requested and available
    if (options?.showSegments && transcriptionResult.segments && transcriptionResult.segments.length > 0) {
        lines.push(`\n### æ®µè½åˆ†æ®µ\n`);
        lines.push('<details><summary>ğŸ“‘ å±•å¼€æŸ¥çœ‹åˆ†æ®µ</summary>\n');
        transcriptionResult.segments.forEach(segment => {
            const start = segment.start.toFixed(2);
            const end = segment.end.toFixed(2);
            lines.push(`\n**æ®µè½ ${segment.id}** \`[${start}s - ${end}s]\`\n`);
            lines.push(`${segment.text}\n`);
        });
        lines.push('</details>');
    }

    return {
        ok: true,
        content: lines.join('\n'),
        usage: null
    };
};

/**
 * Convert ITextToSpeechResult to ICompletionResult for display in chat
 * @param ttsResult - Text-to-speech result
 * @param options - Conversion options
 * @returns ICompletionResult with audio player and download link
 */
export const ttsResultToCompletion = (
    ttsResult: ITextToSpeechResult,
    options?: {
        showInputText?: boolean;
        inputText?: string;
    }
): ICompletionResult => {
    if (!ttsResult.ok) {
        return {
            ok: false,
            content: `**è¯­éŸ³åˆæˆå¤±è´¥**\n\n${ttsResult.error}`,
            usage: null
        };
    }

    const lines: string[] = [];

    // Show input text if requested - ä½¿ç”¨æŠ˜å å¤„ç†é•¿æ–‡æœ¬
    if (options?.showInputText && options.inputText) {
        const inputText = options.inputText;
        const MAX_PREVIEW_LENGTH = 100;

        lines.push(`### è¾“å…¥æ–‡æœ¬\n`);

        if (inputText.length <= MAX_PREVIEW_LENGTH) {
            // çŸ­æ–‡æœ¬ç›´æ¥æ˜¾ç¤ºå¼•ç”¨æ ¼å¼
            lines.push(`${inputText.split('\n').map(l => '> ' + l).join('\n')}\n`);
        } else {
            // é•¿æ–‡æœ¬ä½¿ç”¨ details æŠ˜å 
            const preview = inputText.substring(0, MAX_PREVIEW_LENGTH).trim();
            lines.push(`> ${preview}...`);
            lines.push(`\n<details><summary>ğŸ“„ å±•å¼€å®Œæ•´è¾“å…¥ (${inputText.length} å­—ç¬¦)</summary>\n`);
            lines.push('```txt');
            lines.push(inputText);
            lines.push('```');
            lines.push('</details>\n');
        }
    }

    // Add audio player
    lines.push(`### ç”Ÿæˆçš„è¯­éŸ³\n`);

    // HTML5 audio player
    const format = ttsResult.format || 'mp3';
    lines.push(`<audio controls src="${ttsResult.audioUrl}" type="audio/${format}" />`);

    lines.push('\nè¯·å°½å¿«ä¸‹è½½ä¿å­˜, èµ„æºåœ¨é¡µé¢å…³é—­åå¯èƒ½æ— æ³•è®¿é—®ã€‚');

    // Add metadata
    const metadata: string[] = [];
    if (ttsResult.format) metadata.push(`æ ¼å¼: ${ttsResult.format}`);
    if (ttsResult.audio) {
        metadata.push(`å¤§å°: ${formatFileSize(ttsResult.audio.size)}`);
    }

    if (metadata.length > 0) {
        lines.push(`\n*${metadata.join(' | ')}*`);
    }


    return {
        ok: true,
        content: lines.join('\n'),
        usage: null
    };
};
